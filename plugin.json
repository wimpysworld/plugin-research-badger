{
  "id": "c98a694c-74c7-426f-8aaa-24b52f2a3942",
  "uuid": "c98a694c-74c7-426f-8aaa-24b52f2a3942",
  "title": "Research Badger",
  "iconURL": "https://raw.githubusercontent.com/wimpysworld/plugin-research-badger/refs/heads/main/icon.png",
  "oauthConfig": null,
  "userSettings": [
    {
      "name": "serpAPIKey",
      "type": "password",
      "label": "Serp API Key",
      "required": true,
      "description": "Serp API is used for the Web Search tool. Sign up from serpapi.com to get an API key."
    },
    {
      "name": "firecrawlApiKey",
      "type": "password",
      "label": "Firecrawl API Key",
      "required": true,
      "description": "Firecrawl API is used for the Read Web Page tool. Get your API key at https://www.firecrawl.dev/app/api-keys"
    },
    {
      "name": "researchMode",
      "type": "enum",
      "label": "Digging Intensity",
      "values": ["Scout Dig", "Deep Burrow", "Adaptive Dig"],
      "description": "Select \"Deep Burrow\" if you prefer to have more accurate result (consume more tokens). Default: \"Scout Dig\".",
      "defaultValue": "Scout Dig"
    }
  ],
  "pluginFunctions": [
    {
      "id": "2836fff3-19fe-49ae-894e-3f07ebe73b8e",
      "code": "function update_research_plan() {\n  // This tool does not yet have internal state, returning an acknowledgement is usually enough for LLMs to register and keep track of the todo items. May not work well with less-intelligent models or lists that are too long.\n  return \"Plan updated successfully.\"\n}",
      "name": "Research Plan",
      "openaiSpec": {
        "name": "update_research_plan",
        "parameters": {
          "type": "object",
          "required": ["todos"],
          "properties": {
            "todos": {
              "type": "array",
              "items": {
                "type": "object",
                "required": ["content", "status", "id"],
                "properties": {
                  "id": {
                    "type": "string",
                    "description": "Unique identifier for the TODO item"
                  },
                  "status": {
                    "enum": [
                      "pending",
                      "in_progress",
                      "completed",
                      "cancelled"
                    ],
                    "type": "string",
                    "description": "The current status of the TODO item"
                  },
                  "content": {
                    "type": "string",
                    "description": "The description/content of the TODO item"
                  }
                }
              },
              "minItems": 2,
              "description": "Array of TODO items to write to the workspace to create or update the todo list. If the ID of the todos already exists, they will be merged into the existing todos based on the id field, you can leave unchanged properties undefined."
            },
            "explanation": {
              "type": "string",
              "description": "A short description of the action you take (e.g., \"Creating a plan...\", \"Started item X\",...)"
            }
          }
        },
        "description": "Use this tool to create and manage a structured task list for your current research session. This helps track progress, organize complex investigations, and demonstrate thoroughness.\n\n### When to Use This Tool\n\nUse proactively for:\n1. Complex multi-step research (3+ distinct phases)\n2. Non-trivial investigations requiring careful planning\n3. User explicitly requests research todo list\n4. User provides multiple research topics (numbered/comma-separated)\n5. After receiving new research instructions - capture requirements as todos (use merge=false to add new ones)\n6. After completing research phases - mark complete with merge=true and add follow-ups\n7. When starting new research areas - mark as in_progress (ideally only one at a time)\n\n### When NOT to Use\n\nSkip for:\n1. Single, straightforward questions\n2. Trivial lookups with no organizational benefit\n3. Research completable in < 3 trivial steps\n4. Purely conversational/clarification requests\n5. Don't add a task to verify findings unless asked, or you'll overfocus on validation\n\n### Examples\n\n<example>\n  User: Research the impact of climate change on Arctic wildlife\n  Assistant: *Creates todo list:*\n  1. Analyze temperature trends in Arctic regions\n  2. Identify key Arctic species and habitats\n  3. Review scientific studies on wildlife impacts\n  4. Synthesize findings and correlations\n<reasoning>\n  Multi-phase research with dependencies requiring systematic investigation.\n</reasoning>\n</example>\n\n<example>\n  User: Compare healthcare systems across Nordic countries\n  Assistant: *Creates todo list with specific items for each country's system, funding models, outcomes, and comparative analysis*\n\n<reasoning>\n  Complex comparative research requiring systematic tracking across multiple systems.\n</reasoning>\n</example>\n\n<example>\n  User: Investigate renewable energy adoption, economic impacts, policy frameworks, and future projections.\n  Assistant: *Creates todo list breaking down each research area into specific investigation tasks*\n\n<reasoning>\n  Multiple complex research areas provided as list requiring organized investigation management.\n</reasoning>\n</example>\n\n<example>\n  User: Research why my company's market share is declining - analyze competitors, market trends, customer feedback.\n  Assistant: *Creates todo list: 1) Competitor analysis, 2) Market trend research, 3) Customer sentiment analysis, 4) Internal factor review, 5) Strategic recommendations*\n\n<reasoning>\n  Business analysis requires multiple research phases across different data sources.\n</reasoning>\n</example>\n\n### Examples of When NOT to Use the Todo List\n\n<example>\n  User: What's the capital of France?\n  Assistant: The capital of France is Paris.\n\n<reasoning>\n  Single trivial factual lookup completed in one step.\n</reasoning>\n</example>\n\n<example>\n  User: Explain what photosynthesis is.\n  Assistant: Photosynthesis is the process by which plants convert sunlight into energy...\n\n<reasoning>\n  Informational request with no complex research investigation needed.\n</reasoning>\n</example>\n\n<example>\n  User: Find the current stock price of Apple.\n  Assistant: *Looks up current AAPL price* Apple (AAPL) is currently trading at...\n\n<reasoning>\n  Single straightforward data lookup with immediate results.\n</reasoning>\n</example>\n\n<example>\n  User: What does GDP stand for?\n  Assistant: GDP stands for Gross Domestic Product...\n\n<reasoning>\n  Simple definition request with no multi-step research required.\n</reasoning>\n</example>\n\n### Task States and Management\n\n1. **Research States:**\n  - pending: Not yet started\n  - in_progress: Currently investigating\n  - completed: Research finished successfully\n  - cancelled: No longer needed\n\n2. **Research Management:**\n  - Update status in real-time\n  - Mark complete IMMEDIATELY after finishing each phase\n  - Only ONE research area in_progress at a time\n  - Complete current investigations before starting new ones\n\n3. **Research Breakdown:**\n  - Create specific, actionable investigation items\n  - Break complex research into manageable phases\n  - Use clear, descriptive research objectives\n\nWhen in doubt, use this tool. Proactive research management demonstrates thoroughness and ensures complete investigation of requirements."
      },
      "outputType": "respond_to_ai",
      "implementationType": "javascript"
    },
    {
      "id": "7a819d92-c53e-4e13-be8a-112eefa39c17",
      "code": "",
      "name": "Search Web",
      "httpAction": {
        "id": "1ee8a09f-cdb9-4d51-921a-b917deb6b64b",
        "url": "https://cloud.typingmind.com/api/plugins/serp/search?api_key={serpAPIKey}&engine=google&q={query}&json_restrictor=organic_results[].{title,snippet,source,link}",
        "name": "",
        "method": "GET"
      },
      "openaiSpec": {
        "name": "badger_search_web",
        "parameters": {
          "type": "object",
          "required": ["query"],
          "properties": {
            "query": {
              "type": "string",
              "description": "The search term to look up on the web. Be specific and include relevant keywords for better results. For technical queries, include version numbers or dates if relevant."
            },
            "explanation": {
              "type": "string",
              "description": "One sentence explanation as to why this tool is being used, and how it contributes to the goal."
            }
          }
        },
        "description": "Search the web using SERP API (Google search engine) for real-time information about any topic. Use this tool when you need up-to-date information that might not be available in your training data, or when you need to verify current facts. The search results will include relevant snippets and URLs from web pages. This is particularly useful for questions about current events, technology updates, or any topic that requires recent information."
      },
      "outputType": "respond_to_ai",
      "implementationType": "http"
    },
    {
      "id": "40e566af-f012-4dca-90c3-9965f391bfc2",
      "code": "async function extract_web_page(params, userSettings) {\n  if (userSettings.researchMode === 'Deep Burrow') {\n    return await fetch('https://api.firecrawl.dev/v2/scrape', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        Authorization: 'Bearer ' + userSettings.firecrawlApiKey,\n      },\n      body: JSON.stringify({\n        url: params.pageUrl,\n        formats: ['markdown'],\n        onlyMainContent: true,\n      }),\n    }).then((r) => r.json());\n  } else {\n    const json = await fetch('https://api.firecrawl.dev/v2/scrape', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        Authorization: 'Bearer ' + userSettings.firecrawlApiKey,\n      },\n      body: JSON.stringify({\n        url: params.pageUrl,\n        formats: [\n          {\n            type: 'json',\n            prompt: params.extractInstructions,\n          },\n        ],\n      }),\n    }).then((r) => r.json());\n\n    if (userSettings.researchMode === 'Adaptive Dig') {\n      return {\n        result: json,\n        furtherInstructions:\n          'This result is extracted from the original web page. Use the \"read_full_web_page_content\" tool if you need to read the full content of the web page.',\n      };\n    } else {\n      return json;\n    }\n  }\n}\n",
      "name": "Extract Web Page",
      "httpAction": {
        "id": "fe67c640-6a5b-4ff8-bf44-394bccd0d109",
        "url": "https://api.firecrawl.dev/v1/scrape",
        "name": "",
        "method": "POST",
        "hasBody": true,
        "hasHeaders": true,
        "requestBody": "{\n    \"url\": \"{pageUrl}\",\n    \"formats\": [\n        \"markdown\"\n    ],\n    \"onlyMainContent\": true\n}",
        "requestHeaders": "{\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": \"Bearer {firecrawlApiKey}\"\n}"
      },
      "openaiSpec": {
        "name": "extract_web_page",
        "parameters": {
          "type": "object",
          "required": ["pageUrl"],
          "properties": {
            "pageUrl": {
              "type": "string",
              "description": "The URL of the web page to scrape for content."
            },
            "extractInstructions": {
              "type": "string",
              "description": "Describe the data you want to extract from the web page."
            }
          }
        },
        "description": "Retrieves the text content of a web page in markdown format. When in Scout Dig mode, this tool returns an extracted content with only the answer based on the extractInstructions. When in Deep Burrow mode, this tool returns the full content of the web page."
      },
      "outputType": "respond_to_ai",
      "implementationType": "javascript"
    },
    {
      "id": "16f3fbef-df16-4833-8d43-be7e71e8a912",
      "code": "async function read_full_web_page_content(params, userSettings) {\n  if (userSettings.researchMode !== 'Scout Dig') {\n    return await fetch('https://api.firecrawl.dev/v2/scrape', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        Authorization: 'Bearer ' + userSettings.firecrawlApiKey,\n      },\n      body: JSON.stringify({\n        url: params.pageUrl,\n        formats: ['markdown'],\n        onlyMainContent: true,\n      }),\n    }).then((r) => r.json());\n  } else {\n    return \"\\\"read_full_web_page_content\\\" is not allowed in \" + userSettings.researchMode;\n  }\n}",
      "name": "Read Full Web Page",
      "openaiSpec": {
        "name": "read_full_web_page_content",
        "parameters": {
          "type": "object",
          "required": ["pageUrl"],
          "properties": {
            "pageUrl": {
              "type": "string",
              "description": "The URL of the web page to scrape for content."
            }
          }
        },
        "description": "Retrieves the full text content of a web page in markdown format, this will return the full content of the website that may be extremely long."
      },
      "outputType": "respond_to_ai",
      "implementationType": "javascript"
    }
  ],
  "authenticationType": "AUTH_TYPE_NONE",
  "dynamicContextEndpoints": [
    {
      "id": "800bd740-c179-4c63-b566-0a74223fc261",
      "url": "",
      "name": "Research Badger Mode",
      "method": "GET",
      "source": "static",
      "staticContent": "<USER_INPUT>\n**Research Badger**: Enabled.\n**Digging Intensity**: {researchMode}\n</USER_INPUT>\n\nYou are Research Badger, an AI research assistant that relentlessly digs through sources to conduct thorough, comprehensive research on any given topic. Your goal is to gather comprehensive information, analyze it, and present a well-structured report.\n\nDigging Intensity Instructions:\n- **Scout Dig**: In Scout Dig mode, Research Badger will attempt to extract data from online sources using the extract_web_page tool, which saves tokens at a cost of reduced data accuracy. This is the default mode.\n- **Deep Burrow**: Research Badger will read the full content of the online sources to determine the final answer. If the web pages have a lot of content, it can risk consuming a lot of tokens, which is expensive and may exceed the model's context length limit.\n- **Adaptive Dig**: Research Badger will run in Scout Dig mode by default, but may opt in to read full web page content when needed (using the \"read_full_web_page_content\" tool) to get the most accurate answer.\n\nFollow these instructions carefully:\n\n1. Begin by reading the research task:\n<research_task>\n{lastUserMessage}\n</research_task>\n\n2. Create an initial research plan using the planning tool to create a todo list. This plan should outline the main areas of investigation and the steps you'll take to complete the task. Update the status of each todo list item as you progress through your research.\n\n3. Conduct at least one web search to gather information. In Research Badger mode, all information presented must come from the sources of your research. Before using any tools, provide your reasoning for choosing that particular tool.\n\n4. Follow these guidelines while gathering information:\n   - Collect all necessary data to carry out the research task concisely and thoroughly.\n   - Use bullet points or numbered lists for clarity when appropriate.\n   - Don't ask for unnecessary information or information already provided.\n   - Continue researching until all items in your todo list are completed.\n   - Use available tools one at a time to find the requested information.\n   - Gather data from multiple sources to ensure accuracy and comprehensiveness.\n\n5. Cite all sources used with links to the original websites.\n\n6. Once you have gathered all the information, compile a comprehensive report. Use markdown formatting (such as tables and bullet points) and tools (like graphs) to present your findings effectively. Highlight any surprising or interesting details you discovered during your research.\n\n7. Output your final report with the following structure\n   \n   [Title of report]\n   [Include your comprehensive report here, using appropriate formatting]\n   \n   Interesting Findings:\n   [Highlight surprising or noteworthy details]\n   \n   Sources:\n   [List all sources with links]",
      "cacheDurationHours": 1,
      "cacheRefreshPolicy": "REFRESH_NEVER"
    }
  ]
}
